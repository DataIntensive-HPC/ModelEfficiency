`bottleneck` is a tool that can be used as an initial step for debugging
bottlenecks in your program.

It summarizes runs of your script with the Python profiler and PyTorch's
autograd profiler. Because your script will be profiled, please ensure that it
exits in a finite amount of time.

For more complicated uses of the profilers, please see
https://docs.python.org/3/library/profile.html and
https://pytorch.org/docs/master/autograd.html#profiler for more information.
Running environment analysis...
Running your script with cProfile
Matrix Contraction of A1 and A2 = A1A2 
Size of A1
torch.Size([16, 512, 16])
Size of A2
torch.Size([16, 16, 32])
Calculating A2*B2 contradiction
Size of A1B1
torch.Size([16, 32, 16, 32])
Calculating A1*A2B2 contradiction
Size of A1A2B2
torch.Size([512, 16, 32, 16, 32])
Calculating B1*A1A2B2
Size of A1B1A2B2
torch.Size([512, 512, 32, 32])
Running your script with the autograd profiler...
Matrix Contraction of A1 and A2 = A1A2 
Size of A1
torch.Size([16, 512, 16])
Size of A2
torch.Size([16, 16, 32])
Calculating A2*B2 contradiction
Size of A1B1
torch.Size([16, 32, 16, 32])
Calculating A1*A2B2 contradiction
Size of A1A2B2
torch.Size([512, 16, 32, 16, 32])
Calculating B1*A1A2B2
Size of A1B1A2B2
torch.Size([512, 512, 32, 32])
Matrix Contraction of A1 and A2 = A1A2 
Size of A1
torch.Size([16, 512, 16])
Size of A2
torch.Size([16, 16, 32])
Calculating A2*B2 contradiction
Size of A1B1
torch.Size([16, 32, 16, 32])
Calculating A1*A2B2 contradiction
Size of A1A2B2
torch.Size([512, 16, 32, 16, 32])
Calculating B1*A1A2B2
Size of A1B1A2B2
torch.Size([512, 512, 32, 32])
--------------------------------------------------------------------------------
  Environment Summary
--------------------------------------------------------------------------------
PyTorch 1.6.0 compiled w/ CUDA 10.2
Running with Python 3.6 and 

`pip3 list` truncated output:
numpy==1.19.2
tntorch==1.0.0
torch==1.6.0
torchtext==0.7.0
torchvision==0.7.0
--------------------------------------------------------------------------------
  cProfile output
--------------------------------------------------------------------------------
         92 function calls (89 primitive calls) in 0.178 seconds

   Ordered by: internal time
   List reduced from 18 to 15 due to restriction <15>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        3    0.174    0.058    0.174    0.058 {built-in method einsum}
        4    0.003    0.001    0.003    0.001 {built-in method randn}
        1    0.000    0.000    0.178    0.178 case3_1.py:1(<module>)
       14    0.000    0.000    0.000    0.000 {built-in method builtins.print}
      6/3    0.000    0.000    0.174    0.058 /home/ozturk.27/ModelEfficiency/VirtualEnv/eminEnv/lib/python3.6/site-packages/torch/functional.py:243(einsum)
        5    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C._TensorBase' objects}
        9    0.000    0.000    0.000    0.000 {built-in method builtins.any}
        3    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
       15    0.000    0.000    0.000    0.000 /home/ozturk.27/ModelEfficiency/VirtualEnv/eminEnv/lib/python3.6/site-packages/torch/functional.py:317(<genexpr>)
        3    0.000    0.000    0.000    0.000 /home/ozturk.27/ModelEfficiency/VirtualEnv/eminEnv/lib/python3.6/site-packages/torch/_overrides.py:779(has_torch_function)
        3    0.000    0.000    0.000    0.000 /home/ozturk.27/ModelEfficiency/VirtualEnv/eminEnv/lib/python3.6/site-packages/torch/_VF.py:13(__getattr__)
        6    0.000    0.000    0.000    0.000 /home/ozturk.27/ModelEfficiency/VirtualEnv/eminEnv/lib/python3.6/site-packages/torch/_overrides.py:792(<genexpr>)
        1    0.000    0.000    0.178    0.178 {built-in method builtins.exec}
        3    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}
        6    0.000    0.000    0.000    0.000 {built-in method builtins.len}


--------------------------------------------------------------------------------
  autograd profiler output (CUDA mode)
--------------------------------------------------------------------------------
        top 15 events sorted by cpu_time_total

	Because the autograd profiler uses the CUDA event API,
	the CUDA time column reports approximately max(cuda_time, cpu_time).
	Please ignore this output if your code does not use CUDA.

-----------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
Name         Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes                                   
-----------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
einsum       37.80%           144.018ms        37.80%           144.018ms        144.018ms        37.80%           144.015ms        144.015ms        1                []                                             
bmm          31.74%           120.931ms        31.74%           120.931ms        120.931ms        31.74%           120.932ms        120.932ms        1                []                                             
einsum       5.81%            22.138ms         5.81%            22.138ms         22.138ms         5.81%            22.137ms         22.137ms         1                []                                             
bmm          5.65%            21.534ms         5.65%            21.534ms         21.534ms         5.65%            21.534ms         21.534ms         1                []                                             
reshape      5.18%            19.718ms         5.18%            19.718ms         19.718ms         5.18%            19.719ms         19.719ms         1                []                                             
clone        5.16%            19.664ms         5.16%            19.664ms         19.664ms         5.16%            19.664ms         19.664ms         1                []                                             
copy_        5.15%            19.604ms         5.15%            19.604ms         19.604ms         5.15%            19.613ms         19.613ms         1                []                                             
einsum       0.90%            3.446ms          0.90%            3.446ms          3.446ms          0.90%            3.445ms          3.445ms          1                []                                             
bmm          0.74%            2.830ms          0.74%            2.830ms          2.830ms          0.74%            2.830ms          2.830ms          1                []                                             
randn        0.35%            1.331ms          0.35%            1.331ms          1.331ms          0.35%            1.331ms          1.331ms          1                []                                             
randn        0.34%            1.308ms          0.34%            1.308ms          1.308ms          0.34%            1.307ms          1.307ms          1                []                                             
normal_      0.34%            1.306ms          0.34%            1.306ms          1.306ms          0.34%            1.307ms          1.307ms          1                []                                             
normal_      0.33%            1.263ms          0.33%            1.263ms          1.263ms          0.33%            1.264ms          1.264ms          1                []                                             
reshape      0.25%            962.070us        0.25%            962.070us        962.070us        0.25%            962.400us        962.400us        1                []                                             
clone        0.24%            913.203us        0.24%            913.203us        913.203us        0.24%            913.279us        913.279us        1                []                                             
-----------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------  
Self CPU time total: 380.967ms
CUDA time total: 380.974ms

